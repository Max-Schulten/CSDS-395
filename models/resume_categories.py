#!/usr/bin/env python3# -*- coding: utf-8 -*-"""Created on Tue Feb  3 11:45:03 2026@author: maximilianschultenThis script is used to create, test, train, and evaluate a classifierthat maps plain text résumés to a set of given categories."""#%% IMPORTS + CONFIGimport pandas as pdimport numpy as npimport matplotlib.pyplot as pltfrom sklearn.feature_extraction.text import TfidfVectorizerfrom sklearn.metrics import classification_report, confusion_matrixfrom sklearn.linear_model import LogisticRegressionfrom sklearn.model_selection import train_test_split, StratifiedKFoldfrom sklearn.pipeline import Pipelinefrom xgboost import XGBClassifierfrom pprint import pprintRS = 420EXPLORE = True#%% DATAdata = pd.read_csv("../data/resume+categories.csv")print(f"# of examples: {data.shape[0]}")print(f"# of Unique Categories: {data['Category'].nunique()}")# Check class balanceprint(data['Category'].value_counts())X = data['Resume_str']y = data['Category']X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size = 0.2, stratify=y, random_state=RS)print(f"# of training samples: {X_tr.shape[0]}")print(f"# of test samples: {X_te.shape[0]}")print(      """    Since classes are imbalanced, we stratify the holdout set.    Overall, due to the imbalanced nature of the dataset, we    evaluate our models on Macro & Micro f1, per-class     precision, recall, and f1. Confusion matrices are used to    evaluate where errors are being made.    """    )#%% INITIAL TESTINGpipe = Pipeline([    ("tfidf", TfidfVectorizer(        ngram_range=(1, 2),        min_df=5,        max_df=0.9,        stop_words="english"    )),    ("clf", LogisticRegression(max_iter=999))])pipe.fit(X_tr, y_tr)y_pred = pipe.predict(X_te)pprint(classification_report(y_pred, y_te))